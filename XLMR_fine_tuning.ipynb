{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "lR1FxDJenKAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyTorch\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "V_V26zIfuJ1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrbVMatSjDpa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.utils\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "import pandas as pd\n",
        "from transformers import XLMRobertaForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM, TrainingArguments, Trainer, DataCollatorWithPadding, AdamW, get_linear_schedule_with_warmup, XLMRobertaForSequenceClassification, EarlyStoppingCallback\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "from sklearn.utils import resample\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        add_special_tokens=True,\n",
        "        truncation=True)\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1_result = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds)\n",
        "    recall = recall_score(labels, preds)\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1_result,\n",
        "        'mcc': mcc\n",
        "\t}\n",
        "\n",
        "\n",
        "def find_indices(dataset):\n",
        "    \"\"\"Find indices of each label return a list for each label\"\"\"\n",
        "    # Initialize empty lists to store indices for each label\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "\n",
        "    # Find indices of each label\n",
        "    for id, sample in enumerate(dataset):\n",
        "        if sample['label'] == 0:\n",
        "            label_0_indices.append(id)\n",
        "        elif sample['label'] == 1:\n",
        "            label_1_indices.append(id)\n",
        "    return label_0_indices, label_1_indices\n",
        "\n",
        "\n",
        "def downsample_balanced(dataset, max_length):\n",
        "    \"\"\"Determiny the minority class and return balanced samples from the dataset\"\"\"\n",
        "    # Make indices of each label\n",
        "    label_0_indices, label_1_indices = find_indices(dataset)\n",
        "    # Determine the length of the minority class (2528 is the maximum,\n",
        "    # because this is the size of the minority class in the English dataset)\n",
        "    min_length = min(len(label_0_indices), len(label_1_indices), max_length)\n",
        "    # Downsample the majority class to match the length of the minority class\n",
        "    label_0_downsampled = random.sample(label_0_indices, min_length)\n",
        "    label_1_downsampled = random.sample(label_1_indices, min_length)\n",
        "    # Concetenate the downsampled majority class indices with the minority class indices\n",
        "    balanced = label_0_downsampled + label_1_downsampled\n",
        "\n",
        "    print('label_0: ', len(label_0_downsampled))\n",
        "    print('label_1: ', len(label_1_downsampled))\n",
        "\n",
        "    dataset_train_balanced = [dataset[id] for id in balanced]\n",
        "\n",
        "    # Lowercase sentences\n",
        "    #dataset_train_balanced = [{'label': dataset[id]['label'], 'text': dataset[id]['text'].lower()} for id in balanced]\n",
        "    return dataset_train_balanced\n",
        "\n",
        "\n",
        "def make_balanced_dataset_one(dataset):\n",
        "    \"\"\"Make a balanced training dataset\"\"\"\n",
        "    dataset_train_balanced = downsample_balanced(dataset, 2528)\n",
        "    dataset_train_balanced = Dataset.from_list(dataset_train_balanced)\n",
        "    print('train_size: ', len(dataset_train_balanced))\n",
        "    return dataset_train_balanced\n",
        "\n",
        "def make_balanced_dataset_two(dataset_nl, dataset_en):\n",
        "    \"\"\"Make a balanced training dataset\"\"\"\n",
        "    nl_dataset_train_balanced = downsample_balanced(dataset_nl, 1264)\n",
        "    print(nl_dataset_train_balanced)\n",
        "    en_dataset_train_balanced = downsample_balanced(dataset_en, 1264)\n",
        "    dataset_train_balanced = Dataset.from_list(nl_dataset_train_balanced + en_dataset_train_balanced)\n",
        "    print('train_size: ', len(dataset_train_balanced))\n",
        "    return dataset_train_balanced\n",
        "\n",
        "# Make output directory\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "# Set seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Load Dutch CoLa\n",
        "dataset_nl = load_dataset(\"GroNLP/dutch-cola\")\n",
        "\n",
        "# Load English CoLa\n",
        "dataset_en = load_dataset(\"shivkumarganesh/CoLA\")\n",
        "\n",
        "# Remove unnecesary columns from the dataset\n",
        "dataset_nl = dataset_nl.remove_columns(['Source', 'Original ID', 'Original annotation', 'Material added'])\n",
        "dataset_en = dataset_en.remove_columns(['Unnamed: 0', 'id', 'etc'])\n",
        "print(len(dataset_en['train']))\n",
        "\n",
        "# Rename the Sentence and Acceptability columns\n",
        "dataset_nl = dataset_nl.rename_column(\"Sentence\", \"text\")\n",
        "dataset_nl = dataset_nl.rename_column(\"Acceptability\", \"label\")\n",
        "\n",
        "# Make combined nl/en dataset\n",
        "#dataset_train_balanced = make_balanced_dataset_two(dataset_nl['train'], dataset_en['train'])\n",
        "\n",
        "# Make nl dataset\n",
        "dataset_train_balanced = make_balanced_dataset_one(dataset_nl['train'])\n",
        "\n",
        "# Make en dataset\n",
        "#dataset_train_balanced = make_balanced_dataset_one(dataset_en['train'])\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
        "\n",
        "# Add the padding token to the tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset_nl = dataset_nl.map(tokenize, batched=True)\n",
        "tokenized_dataset_train = dataset_train_balanced.map(tokenize, batched=True)\n",
        "\n",
        "# Split the dataset\n",
        "tokenized_train = tokenized_dataset_train\n",
        "tokenized_test = tokenized_dataset_nl['test']\n",
        "tokenized_valid = tokenized_dataset_nl['validation']\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load Roberta\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\"FacebookAI/xlm-roberta-base\", num_labels = 2)\n",
        "\n",
        "# Run the model on GPU\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 4e-5, eps = 1e-8, betas=(0.9, 0.999))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/output',\n",
        "    logging_dir='logs',\n",
        "    learning_rate=4e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=6,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False,\n",
        "    logging_strategy='epoch',\n",
        "    gradient_accumulation_steps=1,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_valid,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None),\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "model.push_to_hub(\"shuisman/xlm-roberta-base-dutch-cola\")\n",
        "\n",
        "# Evaluate model performance\n",
        "trainer.evaluate(tokenized_test)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/output/fine-tuned-xlmr')"
      ]
    }
  ]
}